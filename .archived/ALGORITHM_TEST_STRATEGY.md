# ç®—æ³•åŒ…æµ‹è¯•ç­–ç•¥ä¸æ–¹æ¡ˆ

æœ¬æ–‡æ¡£è¯¦ç»†è¯´æ˜å¦‚ä½•ç³»ç»Ÿæ€§æµ‹è¯•ç®—æ³•SDKåŠç®—æ³•åŒ…çš„åŠŸèƒ½ã€æ€§èƒ½å’Œç¨³å®šæ€§ã€‚

---

## 1. æµ‹è¯•ç±»å‹æ¦‚è§ˆ

| æµ‹è¯•ç±»å‹ | ç›®æ ‡ | è‡ªåŠ¨åŒ– | é¢‘ç‡ | å…³é”®ç¨‹åº¦ |
|---------|------|--------|------|----------|
| **å•å…ƒæµ‹è¯•** | éªŒè¯SDKæ ¸å¿ƒç»„ä»¶ | âœ… | æ¯æ¬¡æäº¤ | ğŸ”´ å¿…é¡» |
| **CLIéªŒè¯æµ‹è¯•** | æ£€æŸ¥ç®—æ³•åŒ…ç»“æ„ | âœ… | æ¯æ¬¡æäº¤ | ğŸ”´ å¿…é¡» |
| **é›†æˆæµ‹è¯•** | å¹³å°-ç®—æ³•ç«¯åˆ°ç«¯ | âœ… | ç‰ˆæœ¬å‘å¸ƒæ—¶ | ğŸ”´ å¿…é¡» |
| **æ€§èƒ½æµ‹è¯•** | æ£€æµ‹è€—æ—¶ã€å†…å­˜ | âš ï¸ | ç‰ˆæœ¬å‘å¸ƒæ—¶ | ğŸŸ¡ é‡è¦ |
| **å‹åŠ›æµ‹è¯•** | å¹¶å‘ã€ç¨³å®šæ€§ | âš ï¸ | å®šæœŸ | ğŸŸ¡ é‡è¦ |
| **å…¼å®¹æ€§æµ‹è¯•** | å¤šå¹³å°æ”¯æŒ | âŒ | ç‰ˆæœ¬å‘å¸ƒæ—¶ | ğŸŸ¡ é‡è¦ |

---

## 2. å•å…ƒæµ‹è¯•ï¼ˆSDKæ ¸å¿ƒï¼‰

### 2.1 æµ‹è¯•æ–‡ä»¶ç»“æ„

```
tests/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ test_base.py              # æµ‹è¯•BaseAlgorithm
â”œâ”€â”€ test_session.py           # æµ‹è¯•Sessionç®¡ç†
â”œâ”€â”€ test_cli_validate.py      # æµ‹è¯•CLIéªŒè¯
â”œâ”€â”€ test_shared_memory.py     # æµ‹è¯•å…±äº«å†…å­˜è¯»å–ï¼ˆå¾…å®ç°ï¼‰
â”œâ”€â”€ test_runner.py           # æµ‹è¯•Runneråè®®ï¼ˆå¾…å®ç°ï¼‰
â””â”€â”€ test_integration.py       # ç«¯åˆ°ç«¯é›†æˆæµ‹è¯•
```

### 2.2 BaseAlgorithmæµ‹è¯•ï¼ˆtest_base.pyï¼‰

```python
import pytest
from procvision_algorithm_sdk import BaseAlgorithm, Session


class MockAlgorithm(BaseAlgorithm):
    """Mockç®—æ³•ç”¨äºæµ‹è¯•"""

    def __init__(self, pid):
        super().__init__(pid)
        self.setup_called = False
        self.teardown_called = False

    def setup(self):
        self.setup_called = True

    def teardown(self):
        self.teardown_called = True

    def on_step_start(self, step_index, session, context):
        session.set(f"start_{step_index}", True)

    def on_step_finish(self, step_index, session, result):
        result["debug"] = {"finished": True}

    def reset(self, session):
        session.delete("temp_data")

    def get_info(self):
        return {
            "name": "mock_algorithm",
            "version": "0.1.0",
            "steps": [
                {
                    "index": 0,
                    "name": "æ­¥éª¤1",
                    "params": [
                        {"key": "threshold", "type": "float", "default": 0.75}
                    ]
                }
            ]
        }

    def pre_execute(self, step_index, session, shared_mem_id, image_meta, user_params):
        return {"status": "OK"}

    def execute(self, step_index, session, shared_mem_id, image_meta, user_params):
        threshold = user_params.get("threshold", 0.75)
        return {
            "status": "OK" if threshold > 0.5 else "NG",
            "diagnostics": {"confidence": threshold}
        }


class TestBaseAlgorithm:
    """æµ‹è¯•BaseAlgorithmç”Ÿå‘½å‘¨æœŸ"""

    def test_initialization(self):
        """æµ‹è¯•åˆå§‹åŒ–"""
        alg = MockAlgorithm("TEST-01")
        assert alg.pid == "TEST-01"
        assert hasattr(alg, "logger")
        assert hasattr(alg, "diagnostics")

    def test_lifecycle_hooks(self):
        """æµ‹è¯•ç”Ÿå‘½å‘¨æœŸé’©å­"""
        alg = MockAlgorithm("TEST-01")
        session = Session("test-session")

        # setup
        alg.setup()
        assert alg.setup_called

        # on_step_start
        alg.on_step_start(0, session, {})
        assert session.get("start_0") is True

        # execute
        result = alg.execute(0, session, "mem", {"width": 640, "height": 480}, {"threshold": 0.8})
        assert result["status"] == "OK"

        # on_step_finish
        assert "debug" in result
        assert result["debug"]["finished"] is True

        # reset
        session.set("temp_data", "value")
        alg.reset(session)
        assert session.get("temp_data") is None

        # teardown
        alg.teardown()
        assert alg.teardown_called

    def test_abstract_methods(self):
        """æµ‹è¯•æŠ½è±¡æ–¹æ³•å¿…é¡»å®ç°"""
        class IncompleteAlgorithm(BaseAlgorithm):
            def get_info(self):
                return {}
            # ç¼ºå°‘pre_executeå’Œexecute

        alg = IncompleteAlgorithm("TEST")

        # åº”è¯¥èƒ½å®ä¾‹åŒ–ï¼ˆPythonä¸ä¼šé˜»æ­¢ï¼‰
        # ä½†è°ƒç”¨æœªå®ç°çš„æ–¹æ³•ä¼šæŠ¥é”™
        with pytest.raises(NotImplementedError):
            alg.pre_execute(0, Session("test"), "mem", {}, {})
```

### 2.3 SessionçŠ¶æ€ç®¡ç†æµ‹è¯•ï¼ˆtest_session.pyï¼‰

```python
import pytest
from procvision_algorithm_sdk import Session


class TestSession:
    """æµ‹è¯•Sessionéš”ç¦»å’ŒçŠ¶æ€ç®¡ç†"""

    def test_basic_operations(self):
        """æµ‹è¯•åŸºæœ¬çš„get/set/delete"""
        session = Session("session-001")

        # set and get
        session.set("key1", "value1")
        assert session.get("key1") == "value1"

        # delete
        session.delete("key1")
        assert session.get("key1") is None

    def test_session_isolation(self):
        """æµ‹è¯•ä¸åŒSessionä¹‹é—´éš”ç¦»"""
        session1 = Session("session-001")
        session2 = Session("session-002")

        # Session1å†™å…¥
        session1.set("shared_data", "value_from_session1")

        # Session2åº”è¯¥çœ‹ä¸åˆ°
        assert session2.get("shared_data") is None

        # Session2å†™å…¥åŒåkey
        session2.set("shared_data", "value_from_session2")

        # ä¸¤ä¸ªSessionå€¼ä¸åŒ
        assert session1.get("shared_data") == "value_from_session1"
        assert session2.get("shared_data") == "value_from_session2"

    def test_reset(self):
        """æµ‹è¯•resetæ¸…é™¤æ‰€æœ‰çŠ¶æ€"""
        session = Session("session-001")

        # å†™å…¥å¤šä¸ªkey
        session.set("temp1", "value1")
        session.set("temp2", "value2")
        session.set("temp3", "value3")

        # reset
        session.reset()

        # æ‰€æœ‰keyéƒ½è¢«æ¸…é™¤
        assert session.get("temp1") is None
        assert session.get("temp2") is None
        assert session.get("temp3") is None

    def test_context_field(self):
        """æµ‹è¯•contextå­—æ®µ"""
        context = {
            "product_code": "A01",
            "operator": "user001",
            "trace_id": "trace-1234"
        }
        session = Session("session-001", context=context)

        assert session.context["product_code"] == "A01"
        assert session.context["trace_id"] == "trace-1234"

        # contextæ˜¯åªè¯»çš„ï¼ˆä¸åº”è¢«ä¿®æ”¹ï¼‰
        # state_storeä¸contextåˆ†ç¦»
        session.set("temp_data", "value")
        assert session.get("temp_data") == "value"
        assert "temp_data" not in session.context
```

### 2.4 å…±äº«å†…å­˜æµ‹è¯•ï¼ˆtest_shared_memory.pyï¼‰

**æ³¨æ„**ï¼šå½“å‰shared_memory.pyæ˜¯stubå®ç°ï¼Œéœ€è¦å…ˆå®ç°çœŸå®ç‰ˆæœ¬ã€‚

```python
import pytest
import numpy as np
from procvision_algorithm_sdk import read_image_from_shared_memory
import tempfile
import os


class TestSharedMemory:
    """æµ‹è¯•å…±äº«å†…å­˜å›¾åƒè¯»å–ï¼ˆå¾…å®ç°ï¼‰"""

    @pytest.mark.skip(reason="shared_memory.pyæ˜¯stubå®ç°ï¼Œéœ€å®ç°çœŸå®ç‰ˆæœ¬")
    def test_read_image(self):
        """æµ‹è¯•è¯»å–çœŸå®å›¾åƒ"""
        # å‡†å¤‡æµ‹è¯•å›¾åƒ
        test_image = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)

        # å†™å…¥å…±äº«å†…å­˜ï¼ˆè¿™é‡Œéœ€è¦SDKæä¾›writeå‡½æ•°ï¼‰
        from procvision_algorithm_sdk import write_image_to_shared_memory
        shared_mem_id = "test_mem_001"
        write_image_to_shared_memory(shared_mem_id, test_image)

        # è¯»å–
        image_meta = {
            "width": 640,
            "height": 480,
            "channels": 3,
            "dtype": "uint8"
        }
        result = read_image_from_shared_memory(shared_mem_id, image_meta)

        # éªŒè¯
        assert result.shape == test_image.shape
        assert result.dtype == test_image.dtype
        assert np.array_equal(result, test_image)

    @pytest.mark.skip(reason="shared_memory.pyæ˜¯stubå®ç°")
    def test_different_formats(self):
        """æµ‹è¯•ä¸åŒå›¾åƒæ ¼å¼"""
        formats = [
            (640, 480, 3, np.uint8),   # RGB
            (640, 480, 1, np.uint8),   # ç°åº¦
            (640, 480, 3, np.float32), # æµ®ç‚¹
            (800, 600, 3, np.uint8),   # ä¸åŒåˆ†è¾¨ç‡
        ]

        for width, height, channels, dtype in formats:
            img = np.random.randint(0, 255, (height, width, channels), dtype=dtype)
            # ... ç±»ä¼¼test_read_image

    @pytest.mark.skip(reason="shared_memory.pyæ˜¯stubå®ç°")
    def test_concurrent_access(self):
        """æµ‹è¯•å¤šä¸ªç®—æ³•å®ä¾‹åŒæ—¶è¯»å–"""
        # æ¨¡æ‹Ÿå¤šå·¥ä½åŒæ—¶æ£€æµ‹
        import threading

        def read_thread(mem_id, result_dict):
            image_meta = {"width": 640, "height": 480, "channels": 3}
            img = read_image_from_shared_memory(mem_id, image_meta)
            result_dict[mem_id] = img.shape

        threads = []
        results = {}

        for i in range(5):
            mem_id = f"test_mem_{i}"
            t = threading.Thread(target=read_thread, args=(mem_id, results))
            threads.append(t)
            t.start()

        for t in threads:
            t.join()

        # æ‰€æœ‰çº¿ç¨‹éƒ½æˆåŠŸè¯»å–
        assert len(results) == 5
```

---

## 3. CLIéªŒè¯æµ‹è¯•

### 3.1 éªŒè¯ç®—æ³•åŒ…ç»“æ„ï¼ˆtest_cli_validate.pyï¼‰

```python
import json
import os
import tempfile
import zipfile
from procvision_algorithm_sdk.cli import validate


class TestCLIValidate:
    """æµ‹è¯•CLIéªŒè¯åŠŸèƒ½"""

    def test_validate_complete_algorithm(self):
        """æµ‹è¯•å®Œæ•´çš„ç®—æ³•åŒ…"""
        with tempfile.TemporaryDirectory() as tmpdir:
            # 1. åˆ›å»ºç®—æ³•ç»“æ„
            os.makedirs(f"{tmpdir}/wheels")

            # manifest.json
            manifest = {
                "name": "test_algorithm",
                "version": "0.1.0",
                "entry_point": "main:TestAlgorithm",
                "supported_pids": ["TEST-01"]
            }
            with open(f"{tmpdir}/manifest.json", "w") as f:
                json.dump(manifest, f)

            # main.py
            main_py = """
from procvision_algorithm_sdk import BaseAlgorithm, Session

class TestAlgorithm(BaseAlgorithm):
    def get_info(self):
        return {
            "name": "test_algorithm",
            "version": "0.1.0",
            "steps": [{"index": 0, "name": "æ£€æµ‹", "params": []}]
        }

    def pre_execute(self, step_index, session, shared_mem_id, image_meta, user_params):
        return {"status": "OK"}

    def execute(self, step_index, session, shared_mem_id, image_meta, user_params):
        return {"status": "OK", "diagnostics": {"confidence": 0.9}}
"""
            with open(f"{tmpdir}/main.py", "w") as f:
                f.write(main_py)

            # requirements.txt
            with open(f"{tmpdir}/requirements.txt", "w") as f:
                f.write("")

            # 2. æ‰§è¡ŒéªŒè¯
            report = validate(project=tmpdir, manifest=None, zip_path=None)

            # 3. éªŒè¯ç»“æœ
            assert report["summary"]["status"] == "PASS"
            assert report["summary"]["failed"] == 0

            # æ£€æŸ¥å…³é”®éªŒè¯é¡¹
            checks = {c["name"]: c for c in report["checks"]}
            assert checks["manifest_exists"]["result"] == "PASS"
            assert checks["entry_import"]["result"] == "PASS"
            assert checks["io_contract_status"]["result"] == "PASS"

    def test_validate_missing_manifest(self):
        """æµ‹è¯•ç¼ºå°‘manifest.json"""
        with tempfile.TemporaryDirectory() as tmpdir:
            report = validate(project=tmpdir, manifest=None, zip_path=None)

            assert report["summary"]["status"] == "FAIL"
            assert report["checks"][0]["name"] == "manifest_exists"
            assert report["checks"][0]["result"] == "FAIL"

    def test_validate_missing_fields_in_manifest(self):
        """æµ‹è¯•manifestç¼ºå°‘å¿…éœ€å­—æ®µ"""
        with tempfile.TemporaryDirectory() as tmpdir:
            # åˆ›å»ºç¼ºå°‘supported_pidsçš„manifest
            manifest = {
                "name": "test",
                "version": "0.1.0"  # ç¼ºå°‘entry_pointå’Œsupported_pids
            }
            with open(f"{tmpdir}/manifest.json", "w") as f:
                json.dump(manifest, f)

            report = validate(project=tmpdir, manifest=None, zip_path=None)

            checks = {c["name"]: c for c in report["checks"]}
            assert checks["manifest_fields"]["result"] == "FAIL"

    def test_validate_zip_package(self):
        """æµ‹è¯•éªŒè¯ZIPåŒ…"""
        with tempfile.TemporaryDirectory() as tmpdir:
            # åˆ›å»ºç®—æ³•æ–‡ä»¶
            # ... åŒä¸Š ...

            # æ‰“åŒ…æˆZIP
            zip_path = f"{tmpdir}/algorithm.zip"
            with zipfile.ZipFile(zip_path, "w") as z:
                z.write(f"{tmpdir}/manifest.json", "manifest.json")
                z.write(f"{tmpdir}/main.py", "main.py")
                z.write(f"{tmpdir}/requirements.txt", "requirements.txt")
                # åˆ›å»ºç©ºçš„wheelsç›®å½•
                z.writestr("wheels/.gitkeep", "")

            # éªŒè¯ZIP
            report = validate(project=None, manifest=None, zip_path=zip_path)

            checks = {c["name"]: c for c in report["checks"]}
            assert checks["zip_manifest"]["result"] == "PASS"
            assert checks["zip_requirements"]["result"] == "PASS"
            assert checks["zip_wheels"]["result"] == "PASS"
```

### 3.2 ç«¯åˆ°ç«¯é›†æˆæµ‹è¯•

```python
import subprocess
import time
import json
from procvision_algorithm_sdk import Session


class TestEndToEnd:
    """ç«¯åˆ°ç«¯é›†æˆæµ‹è¯•ï¼ˆæ¨¡æ‹Ÿå¹³å°-ç®—æ³•äº¤äº’ï¼‰"""

    @pytest.fixture
    def algorithm_zip(self):
        """åˆ›å»ºæµ‹è¯•ç”¨çš„ç®—æ³•ZIPåŒ…"""
        # è¿™é‡Œåº”è¯¥ç”Ÿæˆä¸€ä¸ªæµ‹è¯•ç®—æ³•åŒ…
        # æˆ–è€…ä½¿ç”¨sdk_sampleï¼ˆå¾…åˆ›å»ºï¼‰
        pass

    def test_algorithm_lifecycle(self):
        """æµ‹è¯•ç®—æ³•å®Œæ•´ç”Ÿå‘½å‘¨æœŸ"""
        # 1. å¯åŠ¨ç®—æ³•è¿›ç¨‹ï¼ˆæ¨¡æ‹ŸRunnerï¼‰
        proc = subprocess.Popen(
            ["python", "-m", "main", "serve"],  # å‡è®¾main.pyæ”¯æŒserveæ¨¡å¼
            stdin=subprocess.PIPE,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True
        )

        try:
            # 2. æ¡æ‰‹ï¼ˆå¾…Runnerå®ç°ï¼‰
            # stdin.write('{"type":"hello","sdk_version":"0.1.0"}\n')
            # response = stdout.readline()
            # assert "hello" in response

            # 3. æ‰§è¡Œæ£€æµ‹ï¼ˆæ¨¡æ‹Ÿï¼‰
            request = {
                "type": "call",
                "request_id": "req-001",
                "method": "execute",
                "payload": {
                    "step_index": 0,
                    "session": {"id": "session-001", "state_store": {}},
                    "shared_mem_id": "shm001",
                    "image_meta": {"width": 640, "height": 480, "channels": 3},
                    "user_params": {"threshold": 0.75}
                }
            }

            # 4. éªŒè¯å“åº”
            # ... å¾…Runnerå®ç° ...

            # 5. å…³é—­
            # stdin.write('{"type":"shutdown"}\n')
            pass

        finally:
            proc.terminate()
            proc.wait(timeout=5)
```

---

## 4. æ€§èƒ½æµ‹è¯•

### 4.1 æ£€æµ‹è€—æ—¶æµ‹è¯•

```python
import time
import statistics
from procvision_algorithm_sdk import Session


class TestPerformance:
    """æ€§èƒ½åŸºå‡†æµ‹è¯•"""

    def test_detection_latency(self):
        """æµ‹è¯•å•æ¬¡æ£€æµ‹è€—æ—¶"""
        # åŠ è½½ç®—æ³•
        from main import MyDetectionAlgorithm
        alg = MyDetectionAlgorithm("TEST-01")
        alg.setup()

        session = Session("test-session")
        image_meta = {"width": 640, "height": 480, "channels": 3}

        # é¢„çƒ­ï¼ˆæ’é™¤é¦–æ¬¡åŠ è½½å»¶è¿Ÿï¼‰
        for _ in range(3):
            alg.execute(0, session, "mem", image_meta, {"threshold": 0.75})

        # æ­£å¼æµ‹è¯•
        latencies = []
        for i in range(100):  # æµ‹è¯•100æ¬¡
            start = time.time()
            result = alg.execute(0, session, "mem", image_meta, {"threshold": 0.75})
            end = time.time()

            assert result["status"] == "OK"
            latencies.append((end - start) * 1000)  # ms

        # ç»Ÿè®¡åˆ†æ
        avg_latency = statistics.mean(latencies)
        p95_latency = statistics.quantiles(latencies, n=20)[18]  # 95åˆ†ä½
        p99_latency = statistics.quantiles(latencies, n=100)[98]  # 99åˆ†ä½

        print(f"\næ€§èƒ½æµ‹è¯•ç»“æœ:")
        print(f"  å¹³å‡è€—æ—¶: {avg_latency:.2f}ms")
        print(f"  95åˆ†ä½: {p95_latency:.2f}ms")
        print(f"  99åˆ†ä½: {p99_latency:.2f}ms")
        print(f"  æœ€å°: {min(latencies):.2f}ms")
        print(f"  æœ€å¤§: {max(latencies):.2f}ms")

        # æ–­è¨€æ€§èƒ½è¾¾æ ‡ï¼ˆä¾‹å¦‚ï¼šå¹³å‡<100msï¼Œ99åˆ†ä½<200msï¼‰
        assert avg_latency < 100, f"å¹³å‡è€—æ—¶è¿‡é«˜: {avg_latency:.2f}ms"
        assert p99_latency < 200, f"99åˆ†ä½è€—æ—¶è¿‡é«˜: {p99_latency:.2f}ms"

        alg.teardown()

    def test_memory_usage(self):
        """æµ‹è¯•å†…å­˜å ç”¨"""
        import psutil
        import os

        from main import MyDetectionAlgorithm

        process = psutil.Process(os.getpid())

        # æµ‹è¯•å‰å†…å­˜
        mem_before = process.memory_info().rss / 1024 / 1024  # MB

        # åŠ è½½ç®—æ³•
        alg = MyDetectionAlgorithm("TEST-01")
        alg.setup()

        mem_after_setup = process.memory_info().rss / 1024 / 1024
        print(f"\nå†…å­˜ä½¿ç”¨:")
        print(f"  Setupå‰: {mem_before:.2f}MB")
        print(f"  Setupå: {mem_after_setup:.2f}MB")
        print(f"  æ¨¡å‹å ç”¨: {mem_after_setup - mem_before:.2f}MB")

        # æ‰§è¡Œå¤šæ¬¡æ£€æµ‹
        session = Session("test-session")
        image_meta = {"width": 640, "height": 480, "channels": 3}

        for _ in range(10):
            alg.execute(0, session, "mem", image_meta, {})

        mem_after_execution = process.memory_info().rss / 1024 / 1024
        print(f"  æ‰§è¡Œå: {mem_after_execution:.2f}MB")
        print(f"  å¢é•¿: {mem_after_execution - mem_after_setup:.2f}MB")

        # æ£€æŸ¥æ˜¯å¦æœ‰å†…å­˜æ³„æ¼ï¼ˆå¢é•¿<50MBï¼‰
        assert mem_after_execution - mem_after_setup < 50

        alg.teardown()

    def test_throughput(self):
        """æµ‹è¯•ååé‡ï¼ˆæ¯ç§’æ£€æµ‹æ¬¡æ•°ï¼‰"""
        from main import MyDetectionAlgorithm

        alg = MyDetectionAlgorithm("TEST-01")
        alg.setup()

        session = Session("test-session")
        image_meta = {"width": 640, "height": 480}

        # æµ‹è¯•10ç§’å†…çš„æ£€æµ‹æ¬¡æ•°
        duration = 10  # ç§’
        start_time = time.time()
        count = 0

        while time.time() - start_time < duration:
            alg.execute(0, session, "mem", image_meta, {})
            count += 1

        throughput = count / duration
        print(f"\nååé‡: {throughput:.2f} FPS")

        assert throughput > 5, f"ååé‡è¿‡ä½: {throughput:.2f} FPS"

        alg.teardown()
```

### 4.2 å¤šåœºæ™¯æ€§èƒ½å¯¹æ¯”

```python
@pytest.mark.parametrize("image_size", [
    (320, 240),   # å°
    (640, 480),   # ä¸­
    (1280, 720),  # å¤§
    (1920, 1080)  # è¶…å¤§
])
def test_performance_different_resolutions(self, image_size):
    """æµ‹è¯•ä¸åŒåˆ†è¾¨ç‡ä¸‹çš„æ€§èƒ½"""
    from main import MyDetectionAlgorithm

    alg = MyDetectionAlgorithm("TEST-01")
    alg.setup()

    session = Session("test-session")
    width, height = image_size
    image_meta = {"width": width, "height": height, "channels": 3}

    # é¢„çƒ­
    alg.execute(0, session, "mem", image_meta, {})

    # æµ‹è¯•
    start = time.time()
    for _ in range(10):
        alg.execute(0, session, "mem", image_meta, {})
    end = time.time()

    avg_latency = (end - start) / 10 * 1000
    print(f"{width}x{height}: {avg_latency:.2f}ms")

    # ç¡®ä¿å¤§åˆ†è¾¨ç‡ä¹Ÿèƒ½æ»¡è¶³SLO
    if width <= 640:
        assert avg_latency < 50
    elif width <= 1280:
        assert avg_latency < 150
    else:
        assert avg_latency < 300

    alg.teardown()
```

---

## 5. é”™è¯¯åœºæ™¯æµ‹è¯•

### 5.1 å¯æ¢å¤é”™è¯¯æµ‹è¯•

```python
import pytest
from procvision_algorithm_sdk import RecoverableError
from main import MyDetectionAlgorithm


class TestRecoverableErrors:
    """æµ‹è¯•å¯æ¢å¤é”™è¯¯åœºæ™¯"""

    def test_insufficient_lighting(self):
        """æµ‹è¯•å…‰ç…§ä¸è¶³"""
        alg = MyDetectionAlgorithm("TEST-01")
        alg.setup()

        session = Session("test-session")
        image_meta = {"width": 640, "height": 480}

        # è®¾ç½®æä½çš„äº®åº¦é˜ˆå€¼ï¼ˆä¸€å®šä¼šè§¦å‘é”™è¯¯ï¼‰
        user_params = {"brightness_threshold": 999}

        result = alg.pre_execute(0, session, "mem", image_meta, user_params)

        # éªŒè¯è¿”å›é”™è¯¯ä¿¡æ¯
        assert result["status"] == "ERROR"
        assert result["error_type"] == "recoverable"
        assert result["suggest_action"] == "retry"
        assert "å…‰ç…§ä¸è¶³" in result["message"]

        alg.teardown()

    def test_camera_disconnected(self):
        """æµ‹è¯•ç›¸æœºæ–­å¼€ï¼ˆæ¨¡æ‹Ÿï¼‰"""
        alg = MyDetectionAlgorithm("TEST-01")
        alg.setup()

        session = Session("test-session")

        # æ¨¡æ‹Ÿå…±äº«å†…å­˜IDæ— æ•ˆ
        result = alg.execute(0, session, "invalid_mem_id", {"width": 640}, {})

        # åº”è¯¥è¿”å›recoverable error
        assert result["status"] == "ERROR"
        assert result["error_type"] == "recoverable"
        assert result["suggest_action"] == "retry"

        alg.teardown()

    def test_network_timeout(self):
        """æµ‹è¯•ç½‘ç»œè¶…æ—¶"""
        # å¦‚æœç®—æ³•ä¾èµ–å¤–éƒ¨æœåŠ¡ï¼ˆä¸æ¨èï¼‰
        pass
```

### 5.2 ä¸å¯æ¢å¤é”™è¯¯æµ‹è¯•

```python
import pytest
from procvision_algorithm_sdk import FatalError
from main import MyDetectionAlgorithm
import os


class TestFatalErrors:
    """æµ‹è¯•ä¸å¯æ¢å¤é”™è¯¯åœºæ™¯"""

    def test_model_file_missing(self):
        """æµ‹è¯•æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨"""
        # ä¸´æ—¶é‡å‘½åæ¨¡å‹æ–‡ä»¶
        model_path = "assets/defect_detector.pt"
        if os.path.exists(model_path):
            os.rename(model_path, model_path + ".backup")

        try:
            alg = MyDetectionAlgorithm("TEST-01")

            # setupåº”è¯¥æŠ›å‡ºFatalError
            with pytest.raises(FatalError):
                alg.setup()

        finally:
            # æ¢å¤æ¨¡å‹æ–‡ä»¶
            if os.path.exists(model_path + ".backup"):
                os.rename(model_path + ".backup", model_path)

    def test_invalid_model_format(self):
        """æµ‹è¯•æ¨¡å‹æ ¼å¼æŸå"""
        alg = MyDetectionAlgorithm("TEST-01")

        # åˆ›å»ºä¸€ä¸ªæŸåçš„æ¨¡å‹æ–‡ä»¶
        with open("assets/corrupted_model.pt", "wb") as f:
            f.write(b"this is not a valid model")

        # ä¿®æ”¹ç®—æ³•ä½¿ç”¨æŸåçš„æ¨¡å‹
        alg.model_path = "assets/corrupted_model.pt"

        with pytest.raises(FatalError):
            alg.setup()

    def test_unsupported_pid(self):
        """æµ‹è¯•ä¸æ”¯æŒçš„äº§å“å‹å·"""
        alg = MyDetectionAlgorithm("TEST-01")
        alg.setup()

        session = Session("test-session")

        # åœ¨get_infoä¸­æœªå£°æ˜æ”¯æŒçš„PID
        result = alg.execute(0, session, "mem", {"width": 640}, {})

        # å¯ä»¥è¿”å›ERRORæˆ–æŠ›å‡ºå¼‚å¸¸
        assert result["status"] in ["ERROR", "NG"]

        alg.teardown()
```

### 5.3 è¾¹ç•Œå€¼æµ‹è¯•

```python
@pytest.mark.parametrize("threshold,expected_status", [
    (0.0, "NG"),      # é˜ˆå€¼è¿‡ä½
    (0.49, "NG"),     # ç•¥ä½äºboundary
    (0.5, "OK"),      # æ­£å¥½åœ¨boundary
    (0.51, "OK"),     # ç•¥é«˜äºboundary
    (1.0, "OK"),      # é˜ˆå€¼è¿‡é«˜
])
def test_threshold_boundary(self, threshold, expected_status):
    """æµ‹è¯•é˜ˆå€¼è¾¹ç•Œå€¼"""
    from main import MyDetectionAlgorithm

    alg = MyDetectionAlgorithm("TEST-01")
    alg.setup()

    session = Session("test-session")
    image_meta = {"width": 640, "height": 480}

    result = alg.execute(0, session, "mem", image_meta, {"threshold": threshold})

    assert result["status"] == expected_status

    alg.teardown()
```

---

## 6. å¹¶å‘ä¸å‹åŠ›æµ‹è¯•

### 6.1 Sessionå¹¶å‘æµ‹è¯•

```python
import threading
from procvision_algorithm_sdk import Session
from main import MyDetectionAlgorithm


class TestConcurrency:
    """æµ‹è¯•å¹¶å‘åœºæ™¯"""

    def test_concurrent_sessions(self):
        """æµ‹è¯•å¤šä¸ªSessionåŒæ—¶è¿è¡Œ"""
        results = {}
        lock = threading.Lock()

        def detect_thread(session_id):
            alg = MyDetectionAlgorithm("TEST-01")
            alg.setup()

            session = Session(session_id)
            image_meta = {"width": 640, "height": 480}

            # å†™å…¥Sessionç‰¹å®šæ•°æ®
            session.set("thread_id", session_id)

            # æ‰§è¡Œæ£€æµ‹
            result = alg.execute(0, session, "mem", image_meta, {})

            with lock:
                results[session_id] = {
                    "status": result["status"],
                    "session_data": session.get("thread_id")
                }

            alg.teardown()

        # å¯åŠ¨10ä¸ªå¹¶å‘çº¿ç¨‹
        threads = []
        for i in range(10):
            t = threading.Thread(target=detect_thread, args=(f"session-{i}",))
            threads.append(t)
            t.start()

        for t in threads:
            t.join()

        # æ‰€æœ‰çº¿ç¨‹éƒ½å®Œæˆ
        assert len(results) == 10

        # æ¯ä¸ªSessionçš„æ•°æ®æ˜¯éš”ç¦»çš„
        for session_id, result in results.items():
            assert result["session_data"] == session_id

    def test_algorithm_instance_reuse(self):
        """æµ‹è¯•åŒä¸€ç®—æ³•å®ä¾‹å¤„ç†å¤šä¸ªäº§å“"""
        from main import MyDetectionAlgorithm

        alg = MyDetectionAlgorithm("TEST-01")
        alg.setup()

        # æ¨¡æ‹Ÿ100ä¸ªäº§å“è¿ç»­æ£€æµ‹
        for i in range(100):
            session = Session(f"session-{i}")
            image_meta = {"width": 640, "height": 480}

            result = alg.execute(0, session, "mem", image_meta, {})
            assert result["status"] in ["OK", "NG"]

            # æ¯æ¬¡æ£€æµ‹åæ¸…ç†Session
            alg.reset(session)

        alg.teardown()
```

### 6.2 24å°æ—¶ç¨³å®šæ€§æµ‹è¯•

```python
import time


def test_long_running_stability():
    """24å°æ—¶ç¨³å®šæ€§æµ‹è¯•ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
    from main import MyDetectionAlgorithm

    alg = MyDetectionAlgorithm("TEST-01")
    alg.setup()

    start_time = time.time()
    duration = 24 * 60 * 60  # 24å°æ—¶

    count = 0
    errors = 0

    while time.time() - start_time < duration:
        try:
            session = Session(f"session-{count}")
            image_meta = {"width": 640, "height": 480}

            result = alg.execute(0, session, "mem", image_meta, {})

            if result["status"] == "ERROR":
                errors += 1

            count += 1

            # æ¯1000æ¬¡æŠ¥å‘ŠçŠ¶æ€
            if count % 1000 == 0:
                elapsed = time.time() - start_time
                print(f"å·²è¿è¡Œ {elapsed/3600:.1f} å°æ—¶ï¼Œæ£€æµ‹ {count} æ¬¡ï¼Œé”™è¯¯ {errors} æ¬¡")

        except Exception as e:
            errors += 1
            print(f"å¼‚å¸¸: {e}")

    alg.teardown()

    print(f"\n24å°æ—¶ç¨³å®šæ€§æµ‹è¯•ç»“æœ:")
    print(f"  æ€»æ£€æµ‹æ¬¡æ•°: {count}")
    print(f"  é”™è¯¯æ¬¡æ•°: {errors}")
    print(f"  æˆåŠŸç‡: {(count-errors)/count*100:.2f}%")

    # æˆåŠŸç‡åº”>99.9%
    assert (count - errors) / count > 0.999
```

---

## 7. æµ‹è¯•è¦†ç›–ç‡ç›®æ ‡

```bash
# ä½¿ç”¨pytest-covæµ‹é‡è¦†ç›–ç‡
pip install pytest-cov

# è¿è¡Œæµ‹è¯•å¹¶ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š
pytest --cov=procvision_algorithm_sdk --cov-report=html --cov-report=term-missing

# è¦†ç›–ç‡ç›®æ ‡ï¼ˆå»ºè®®ï¼‰
# - è¯­å¥è¦†ç›–ç‡: >85%
# - åˆ†æ”¯è¦†ç›–ç‡: >75%
```

**ç¤ºä¾‹è¾“å‡ºï¼š**
```
Name                                          Stmts   Miss  Cover
-----------------------------------------------------------------
procvision_algorithm_sdk/__init__.py             10      0   100%
procvision_algorithm_sdk/base.py                 35      2    94%
procvision_algorithm_sdk/cli.py                  85     15    82%
procvision_algorithm_sdk/session.py              20      1    95%
procvision_algorithm_sdk/errors.py                4      0   100%
procvision_algorithm_sdk/logger.py               25      3    88%
procvision_algorithm_sdk/diagnostics.py          10      1    90%
procvision_algorithm_sdk/shared_memory.py         8      8     0%  # å¾…å®ç°
-----------------------------------------------------------------
TOTAL                                           197     30    85%
```

---

## 8. å›å½’æµ‹è¯•ç­–ç•¥

### 8.1 ç‰ˆæœ¬å‘å¸ƒå‰æµ‹è¯•æ¸…å•

```bash
# æ¯æ¬¡å‘å¸ƒæ–°ç‰ˆæœ¬æ—¶æ‰§è¡Œ

# 1. å•å…ƒæµ‹è¯•ï¼ˆå¿«é€Ÿï¼‰
pytest tests/ -v

# 2. CLIéªŒè¯ï¼ˆå¿«é€Ÿï¼‰
procvision-sdk validate --project sdk_sample

# 3. æ€§èƒ½æµ‹è¯•ï¼ˆä¸­ç­‰ï¼‰
pytest tests/test_performance.py -v

# 4. é”™è¯¯åœºæ™¯æµ‹è¯•ï¼ˆå¿«é€Ÿï¼‰
pytest tests/test_errors.py -v

# 5. é›†æˆæµ‹è¯•ï¼ˆå¯é€‰ï¼Œéœ€è¦Runnerå®ç°ï¼‰
# pytest tests/test_integration.py -v

# 6. è¦†ç›–ç‡æ£€æŸ¥
pytest --cov=procvision_algorithm_sdk --cov-report=term-missing --cov-fail-under=85
```

### 8.2 GitHub Actionsè‡ªåŠ¨åŒ–

```yaml
# .github/workflows/test.yml
name: SDK Test Suite

on:
  push:
    branches: [ main, dev ]
  pull_request:
    branches: [ main ]

jobs:
  test:
    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.8'

    - name: Install dependencies
      run: |
        pip install -e .
        pip install pytest pytest-cov

    - name: Run unit tests
      run: |
        pytest tests/test_base.py tests/test_session.py tests/test_errors.py -v

    - name: Run CLI tests
      run: |
        pytest tests/test_cli_validate.py -v

    - name: Run performance tests
      run: |
        pytest tests/test_performance.py -v --benchmark-autosave

    - name: Check coverage
      run: |
        pytest --cov=procvision_algorithm_sdk --cov-fail-under=85

    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
```

---

## 9. æµ‹è¯•æ•°æ®ç®¡ç†

### 9.1 æµ‹è¯•å›¾åƒæ•°æ®é›†

```
tests/
â””â”€â”€ data/
    â”œâ”€â”€ ok/
    â”‚   â”œâ”€â”€ product_001.jpg    # åˆæ ¼å“å›¾åƒ
    â”‚   â”œâ”€â”€ product_002.jpg
    â”‚   â””â”€â”€ ...
    â”œâ”€â”€ ng/
    â”‚   â”œâ”€â”€ scratch_001.jpg    # æœ‰åˆ’ç—•
    â”‚   â”œâ”€â”€ stain_001.jpg      # æœ‰æ±¡ç‚¹
    â”‚   â””â”€â”€ ...
    â””â”€â”€ edge_cases/
        â”œâ”€â”€ dark_image.jpg     # å…‰ç…§ä¸è¶³
        â”œâ”€â”€ blurry_image.jpg   # æ¨¡ç³Š
        â””â”€â”€ overexposed.jpg    # è¿‡æ›
```

### 9.2 Mockæ•°æ®ç”Ÿæˆ

```python
import numpy as np
import cv2


def generate_test_image(width=640, height=480, defect_type=None):
    """ç”Ÿæˆæµ‹è¯•å›¾åƒ"""
    # åˆ›å»ºåŸºç¡€å›¾åƒ
    img = np.ones((height, width, 3), dtype=np.uint8) * 200

    if defect_type == "scratch":
        # æ·»åŠ åˆ’ç—•
        cv2.line(img, (100, 100), (300, 100), (50, 50, 50), 2)
    elif defect_type == "stain":
        # æ·»åŠ æ±¡ç‚¹
        cv2.circle(img, (200, 200), 30, (100, 100, 100), -1)
    elif defect_type == "dark":
        # é™ä½äº®åº¦
        img = (img * 0.3).astype(np.uint8)

    return img
```

---

## 10. æµ‹è¯•æŠ¥å‘Šç¤ºä¾‹

æ¯æ¬¡æµ‹è¯•è¿è¡Œååº”ç”Ÿæˆè¯¦ç»†æŠ¥å‘Šï¼š

```
============================= TEST REPORT =============================
æµ‹è¯•æ—¶é—´: 2025-11-20 14:30:00
SDKç‰ˆæœ¬: 0.1.0
ç®—æ³•åŒ…: my_algorithm-v1.0.0-offline.zip

ã€å•å…ƒæµ‹è¯•ã€‘
  æ€»ç”¨ä¾‹: 45
  é€šè¿‡: 43
  å¤±è´¥: 2
  è¦†ç›–ç‡: 87.3%

ã€æ€§èƒ½æµ‹è¯•ã€‘
  å¹³å‡è€—æ—¶: 52.3ms
  95åˆ†ä½: 68.5ms
  ååé‡: 18.5 FPS
  å†…å­˜å ç”¨: 145.6MB

ã€é”™è¯¯åœºæ™¯æµ‹è¯•ã€‘
  å¯æ¢å¤é”™è¯¯: âœ… é€šè¿‡
  ä¸å¯æ¢å¤é”™è¯¯: âœ… é€šè¿‡
  è¾¹ç•Œå€¼: âœ… é€šè¿‡

ã€é›†æˆæµ‹è¯•ã€‘
  å¹³å°é€šä¿¡: âš ï¸ è·³è¿‡ï¼ˆRunneræœªå®ç°ï¼‰
  Sessionéš”ç¦»: âœ… é€šè¿‡

ã€å›å½’æµ‹è¯•ã€‘
  ä¸ä¸Šä¸€ç‰ˆæœ¬å¯¹æ¯”: æ€§èƒ½æå‡ 12%

ç»“è®º: æµ‹è¯•é€šè¿‡ âœ…
=======================================================================
```

---

## 11. å…³é”®æµ‹è¯•æŒ‡æ ‡ï¼ˆKPIï¼‰

| æŒ‡æ ‡ | ç›®æ ‡å€¼ | æµ‹é‡æ–¹æ³• | é¢‘ç‡ |
|------|--------|----------|------|
| **å•å…ƒæµ‹è¯•è¦†ç›–ç‡** | >85% | pytest-cov | æ¯æ¬¡æäº¤ |
| **å¹³å‡æ£€æµ‹è€—æ—¶** | <100ms | æ€§èƒ½æµ‹è¯• | ç‰ˆæœ¬å‘å¸ƒ |
| **95åˆ†ä½è€—æ—¶** | <150ms | æ€§èƒ½æµ‹è¯• | ç‰ˆæœ¬å‘å¸ƒ |
| **ååé‡** | >10 FPS | æ€§èƒ½æµ‹è¯• | ç‰ˆæœ¬å‘å¸ƒ |
| **Sessionéš”ç¦»æ€§** | 100% | å¹¶å‘æµ‹è¯• | ç‰ˆæœ¬å‘å¸ƒ |
| **24hç¨³å®šæ€§** | >99.9% | å‹åŠ›æµ‹è¯• | ç‰ˆæœ¬å‘å¸ƒ |
| **CLIéªŒè¯é€šè¿‡ç‡** | 100% | è‡ªåŠ¨åŒ– | æ¯æ¬¡æäº¤ |

---

## 12. é—®é¢˜è¿½è¸ªä¸ä¿®å¤

### 12.1 æµ‹è¯•å¤±è´¥åˆ†ç±»

```python
# pytestæ ‡è®°å¤±è´¥ç”¨ä¾‹

@pytest.mark.xfail(reason="shared_memoryæœªå®ç°")
def test_shared_memory_read():
    # å·²çŸ¥é—®é¢˜ï¼Œå¾…ä¿®å¤
    pass

@pytest.mark.flaky(reruns=3)  # å¶å°”å¤±è´¥çš„ç”¨ä¾‹
def test_concurrent_access():
    pass

@pytest.mark.skipif(
    os.environ.get("CI") is None,
    reason="ä»…åœ¨CIç¯å¢ƒè¿è¡Œ"
)
def test_integration():
    pass
```

### 12.2 é—®é¢˜ä¿®å¤æµç¨‹

1. **å‘ç°é—®é¢˜**ï¼šæµ‹è¯•å¤±è´¥ â†’ åˆ›å»ºIssue
2. **åˆ†æåŸå› **ï¼šæŸ¥çœ‹æ—¥å¿—ã€å¤ç°é—®é¢˜
3. **ç¼–å†™æµ‹è¯•**ï¼šæ·»åŠ å›å½’æµ‹è¯•ç”¨ä¾‹
4. **ä¿®å¤ä»£ç **ï¼šå®ç°ä¿®å¤
5. **éªŒè¯**ï¼šæµ‹è¯•é€šè¿‡ â†’ æäº¤PR
6. **Code Review**ï¼šè‡³å°‘1äººå®¡æŸ¥

---

## 13. æ€»ç»“

### 13.1 å½“å‰æµ‹è¯•çŠ¶æ€

| æµ‹è¯•æ¨¡å— | çŠ¶æ€ | å¤‡æ³¨ |
|---------|------|------|
| BaseAlgorithm | âœ… å·²å®ç° | tests/test_base.py |
| Session | âœ… å·²å®ç° | tests/test_session.py |
| CLIéªŒè¯ | âœ… å·²å®ç° | tests/test_cli_validate.py |
| å…±äº«å†…å­˜ | âŒ å¾…å®ç° | ä¾èµ–çœŸå®å®ç° |
| Runneråè®® | âŒ å¾…å®ç° | ä¾èµ–çœŸå®å®ç° |
| æ€§èƒ½æµ‹è¯• | âš ï¸ å·²å®ç° | tests/test_performance.py |
| é”™è¯¯åœºæ™¯ | âš ï¸ éƒ¨åˆ†å®ç° | tests/test_errors.py |

### 13.2 ä¸‹ä¸€æ­¥è¡ŒåŠ¨

1. **ç«‹å³è¡ŒåŠ¨ï¼ˆæœ¬å‘¨ï¼‰**ï¼š
   - ç¼–å†™å®Œæ•´çš„sdk_sampleç®—æ³•åŒ…
   - ä¿®å¤CLIæµ‹è¯•ä¸­çš„å¤±è´¥ç”¨ä¾‹

2. **çŸ­æœŸè¡ŒåŠ¨ï¼ˆæœ¬æœˆï¼‰**ï¼š
   - ä¼˜åŒ–æ€§èƒ½æµ‹è¯•ï¼Œæ·»åŠ æ›´å¤šåœºæ™¯
   - å®ç°å¹¶å‘æµ‹è¯•å’Œå‹åŠ›æµ‹è¯•
   - æ·»åŠ è¦†ç›–ç‡æ£€æŸ¥åˆ°CI

3. **é•¿æœŸè¡ŒåŠ¨ï¼ˆä¸‹ç‰ˆæœ¬ï¼‰**ï¼š
   - ç­‰å¾…shared_memoryå’ŒRunnerå®ç°åï¼Œè¡¥å……é›†æˆæµ‹è¯•
   - æ·»åŠ å…¼å®¹æ€§æµ‹è¯•ï¼ˆå¤šå¹³å°ï¼‰
   - å»ºç«‹æ€§èƒ½åŸºçº¿æ•°æ®åº“

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0
**æœ€åæ›´æ–°**: 2025-11-20
**æµ‹è¯•æ¡†æ¶**: pytest 7.0+
